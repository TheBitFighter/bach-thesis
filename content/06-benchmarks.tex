%!TEX spellcheck
%!TEX root = ../bachelor_paper.tex
\documentclass[../bachelor_paper.tex]{subfiles}
\graphicspath{{\subfix{images/}}}
\begin{document}

\chapter{Benchmarks}
    \label{ch:bench}

Over the past decades, a handful of benchmark suits have managed to establish themselves as the de facto industry standard for embedded benchmarking. These suits are heavily distinguished from their desktop counterparts as they fulfill a vastly different purpose. Most of these suits have emerged in the last 20 years and several of them pull heavily from preexisting suits, reusing some of their workloads. The main differences between embedded benchmarks and desktop computing benchmarks are storage and system requirements. Desktop computing benchmarks almost always assume an operating system to be present on the machine and thus perform syscalls and expect commodities like a file system. Embedded benchmarks need a small storage footprint to be able to even fit on the heavily restricted flash space of embedded processors. Additionally, while desktop benchmarks are mostly focused on raw performance, embedded benchmarks often consider additional performance metrics such as power to throughput. In the following we will present the list of benchmarks we selected to test our framework with.

\section{Coremark}
Coremark is a purely synthetic benchmark aimed at providing a single performance score for as many embedded systems as possible. From the list presented here, Coremark is the only fully synthetic benchmark, which makes the comparison against an actual workload much more interesting. The benchmark consists of three main segments, which are list processing, matrix processing, and state machine processing. List processing iterates through a list of data containing either precomputed values or algorithm invocation instructions, where the list itself is also searched, inversed and sorted. Matrix processing mainly strains the compute engine of a core, performing matrix operations which cannot be computed at compile time. These operations are also meant to test the efficiency of a core's compiler optimizations as well as its handling of tight loop operations and \ac{SIMD} instructions. State machine processing mainly strains the control flow part of a core, using \texttt{if}-statements as the list portion is already implemented using \texttt{switch}-statements \cite{gal-onExploringCoremarkBenchmark2012}.

As already mentioned, its synthetic nature makes Coremark an especially interesting target for comparison against an actual demo workload. Coremark's instruction profile also strongly varies over time \cite{gal-onExploringCoremarkBenchmark2012}, which should be reflected in sectional data as explained in \ref{sec:arch/enlynx}.

\section{MiBench}
    \label{sec:bench:mibench}
MiBench came about in 2001 and was a response to \acs{SPEC} on the desktop side as a standardized benchmark computing suite meant for embedded applications. Its intention was to assemble a portable suite of open source software able to run on as many systems as possible and to be as representative as possible \cite{guthausMiBenchFreeCommercially2001}. In contrast to Coremark, MiBench is a compilation of actual problem solving applications and does not contain purely synthetic elements. MiBench is separated into the categories Automotive and
Industrial Control, Network, Security, Consumer Devices, Office Automation, and Telecommunications. Each category consists of a set of programs representative of applications possibly run on processors of said category at the time of benchmark design as seen in table \ref{tab:bench/mibench/apps}. \cite{guthausMiBenchFreeCommercially2001} goes on to show that MiBench has a higher variation in instruction profiles compared to its desktop counterpart \acs{SPEC}2000. Thus, selecting not only the right sub-suite, but also the right program(s) from the chosen sub-suite(s) poses an interesting challenge to solve. However, the benchmark suite also assumes a host operating system for most of it's programs \cite{pallisterBEEBSOpenBenchmarks2013}. This is a rather steep constraint and applications with that requirement will not be tested on our platform.

\begin{table}
    \centering
    \resizebox{\textwidth}{!}{%
    \begin{tabular}{llllll}
        \textbf{Auto./Industrial}   & \textbf{Consumer} & \textbf{Office}   & \textbf{Network}  & \textbf{Security}     & \textbf{Telecom.} \\
        \hline\\[-0.9em]
        basicmath           & jpeg          & ghostscript   & dijkstra  & blowfish enc. & CRC32     \\
        bitcount            & lame          & ispell        & patricia  & blowfish dec. & FFT       \\
        qsort               & mad           & rsynth        & (CRC32)   & pgp sign      & IFFT      \\
        susan (edges)       & tiff2bw       & sphinx        & (sha)     & pgp verify    & ADPCM enc.\\
        susan (corners)     & tiff2rgba     & stringsearch  & (blowfish)& rijndael enc. & ADPCM dec.\\
        susan (smoothing)   & tiffdither    &               &           & rijndael dec. & GSM enc.  \\
                            & tiffmedian    &               &           & sha           &           \\
                            & typeset       &               &           &               &           \\
        \hline
    \end{tabular}}
    \caption{Applications contained in the different sub-suites of MiBench \cite{guthausMiBenchFreeCommercially2001}}
    \label{tab:bench/mibench/apps}
\end{table}

\section{BEEBS}
    \label{sec:bench:beebs}
BEEBS' main focus is the exploration of energy consumption. The corresponding whitepaper was published in 2013 and is designed for embedded applications. BEEBS is a conglomerate of workloads cherry picked from already existing benchmark suites with a main focus on providing applications big enough to be representative while setting as little requirements for the host platform as possible (storage requirements, file system, ...). They group the applications contained by four different categories corresponding to strain exerted on different subsystems of a core under test. Each of the categories, integer operations, floating point operations, memory access intensity, and branching frequency, are marked with either low, medium, or high \cite{pallisterBEEBSOpenBenchmarks2013}. The benchmarks were mostly sourced from the MiBench suite \cite{guthausMiBenchFreeCommercially2001} with 3 applications being derived from the WCET suite \cite{gustafssonMalardalenWCETBenchmarks2010} and one from DSPStone \cite{zivojnovicDSPstoneDSPorientedBenchmarking1994}, as seen in table \ref{tab:bench/beebs/apps}. The table also shows their categorization according to the grouping criteria laid out by \cite{pallisterBEEBSOpenBenchmarks2013}. The resulting set was tested on different architectures representing different tiers of processors. As the main metric to be observed is power consumption, a memory access on an implementation featuring a cache uses a different amount of energy than the same access on an implementation without one. The applications were validated on a Cortex-M0 processor, a simple single core implementation, an XMOS L1, an event driven platform with eight hardware threads, and Epiphany, a super scalar 16-core processor \cite{pallisterBEEBSOpenBenchmarks2013}. The validation was performed by generating instruction traces in order to ensure a large enough spread in operation distribution.

We only use a very limited subset of BEEBS due to availability of ports on the platform tested.

\begin{table}
    \centering
    \begin{tabular}{lllllll}
    \textbf{Name}   & \textbf{Source}   & \textbf{B} & \textbf{M} & \textbf{I} & \textbf{FP}    & \textbf{Category} \\
    \hline\\[-0.9em]
    Blowfish        & MiBench   & L & M & H & L & Security \\
    CRC32           & MiBench   & M & L & H & L & Telecom. \\
    Cubic root solver & MiBench & L & M & H & L & Automotive \\
    Dijkstra        & MiBench   & M & L & H & L & Network  \\
    FDCT            & WCET      & H & H & L & H & Consumer \\
    Float Matmult   & WCET      & M & H & M & M & Automotive, consumer \\
    Integer Matmult & WCET      & M & M & H & L & Automotive \\
    Rijndael        & MiBench   & H & L & M & L & Security \\
    SHA             & MiBench   & H & M & M & L & Network, security \\
    2D FIR          & DSPstone  & H & M & L & H & Automotive, consumer \\
    \hline
    \end{tabular}
    \caption{Applications contained in BEEBS, their origins, and their categorization \cite{pallisterBEEBSOpenBenchmarks2013}}
    \label{tab:bench/beebs/apps}
\end{table}

\section{EmBench}
EmBench is an open source benchmarking suite created in 2019 as the one suite to measure them all. The intention was to displace benchmarks previously tagged as industry standard by assembling a free and open source suite comprised of real world programs maintained by a central organization \cite{jun11EmbenchRecruitingLong2019}. The code is available on their official website \cite{EmbenchModernEmbedded}, at version 1.0 as of writing, and consists of 19 benchmarks. These benchmarks were largely sourced from MiBench \cite{guthausMiBenchFreeCommercially2001} (see Section \ref{sec:bench:mibench}), BEEBS \cite{pallisterBEEBSOpenBenchmarks2013} (see Section \ref{sec:bench:beebs}), and TACleBench \cite{falkTACLeBenchBenchmarkCollection2016}. EmBench reports the geometric mean compared to a reference system as well as standard deviation as the single performance score. Additionally, code size of the target platform in regards to the reference system are also reported. Quite fittingly, RI5CY is the reference system for EmBench \cite{jun11EmbenchRecruitingLong2019}.

\section{Summary}
    \label{sec:bench/sum}
We use the benchmarking suits presented above to test our hardware framework. Due to availability and portability, we were not able to test every single program in each suite, however all programs tested can be seen in Table \ref{tab:bench/sum/run}. Additionally to the suits presented above, other benchmarks were also run due to their availability for the platform. They have been added in the \emph{Custom} category.

\begin{table}
    \centering
    \begin{tabular}{llllll}
        \textbf{Coremark}   & \textbf{MiBench}  & \textbf{EmBench}  & \textbf{BEEBS}    & \textbf{Custom}   \\
        \hline\\[-0.9em]
        Coremark            & basicmath         & aha-mont64        & crc32             & Dhrystone         \\
                            & bitcount          & crc32             & cubic             & median            \\
                            & dijkstra          & cubic             & dijkstra          & multiply          \\
                            & fft               & edn               &                   & rsort             \\
                            & qsort             & huffbench         &                   & sort              \\
                            & stringsearch      & matmult-int       &                   & spmv              \\
                            & susan             & minver            &                   & towers            \\
                            &                   & nbody             &                   & vvadd             \\
                            &                   & nettle-aes        &                   & factorial         \\
                            &                   & nettle-sha256     &                   & nqueens           \\
                            &                   & nsichneu          &                   & tak               \\
                            &                   & picojpeg          &                   &                   \\
                            &                   & qrduino           &                   &                   \\
                            &                   & sglib-combined    &                   &                   \\
                            &                   & slre              &                   &                   \\
                            &                   & st                &                   &                   \\
                            &                   & statemate         &                   &                   \\
                            &                   & ud                &                   &                   \\
                            &                   & wikisort          &                   &
    \end{tabular}
    \caption{Benchmarks run per suite}
    \label{tab:bench/sum/run}
\end{table}

% Render bibliograhy and acronyms if rendered standalone
\isstandalone
\bibliographystyle{IEEEtran}
\bibliography{bibliography}
\subfile{abbreviations.tex}
\fi

\end{document} 
